{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 請結合前面的知識與程式碼，比較不同的 optimizer 與 learning rate 組合對訓練的結果與影響\n",
    "### 常見的 optimizer 包含\n",
    "* SGD\n",
    "* RMSprop\n",
    "* AdaGrad\n",
    "* Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "LEARNING_RATE = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "MOMENTUM = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with LR = 0.100000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.2432 - accuracy: 0.1505 - val_loss: 2.2001 - val_accuracy: 0.1470\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 2.2724 - accuracy: 0.1190 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 2.3039 - accuracy: 0.0984 - val_loss: 2.3039 - val_accuracy: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 2.3044 - accuracy: 0.0977 - val_loss: 2.3039 - val_accuracy: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 12s 237us/step - loss: 2.3039 - accuracy: 0.0990 - val_loss: 2.3048 - val_accuracy: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 12s 238us/step - loss: 2.3043 - accuracy: 0.0977 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 2.3040 - accuracy: 0.0990 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 2.3039 - accuracy: 0.0977 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 2.3041 - accuracy: 0.0979 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 2.3042 - accuracy: 0.0996 - val_loss: 2.3042 - val_accuracy: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 2.3042 - accuracy: 0.1007 - val_loss: 2.3049 - val_accuracy: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 11s 229us/step - loss: 2.3041 - accuracy: 0.0977 - val_loss: 2.3046 - val_accuracy: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 2.3044 - accuracy: 0.1006 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 2.3047 - accuracy: 0.0996 - val_loss: 2.3043 - val_accuracy: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 2.3040 - accuracy: 0.0995 - val_loss: 2.3046 - val_accuracy: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 2.3040 - accuracy: 0.0999 - val_loss: 2.3037 - val_accuracy: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 2.3042 - accuracy: 0.0987 - val_loss: 2.3044 - val_accuracy: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 2.3041 - accuracy: 0.1008 - val_loss: 2.3041 - val_accuracy: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 2.3041 - accuracy: 0.0989 - val_loss: 2.3041 - val_accuracy: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 2.3039 - accuracy: 0.0993 - val_loss: 2.3046 - val_accuracy: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 11s 230us/step - loss: 2.3040 - accuracy: 0.0998 - val_loss: 2.3037 - val_accuracy: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 2.3043 - accuracy: 0.0972 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 2.3040 - accuracy: 0.1023 - val_loss: 2.3050 - val_accuracy: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 11s 229us/step - loss: 2.3044 - accuracy: 0.0972 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 2.3040 - accuracy: 0.1008 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 2.3042 - accuracy: 0.0984 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 2.3041 - accuracy: 0.0979 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 2.3043 - accuracy: 0.0991 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 11s 227us/step - loss: 2.3041 - accuracy: 0.0987 - val_loss: 2.3040 - val_accuracy: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 2.3044 - accuracy: 0.1005 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 2.3041 - accuracy: 0.0980 - val_loss: 2.3047 - val_accuracy: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 2.3038 - accuracy: 0.0995 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 11s 227us/step - loss: 2.3044 - accuracy: 0.0976 - val_loss: 2.3032 - val_accuracy: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 2.3039 - accuracy: 0.1000 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 2.3038 - accuracy: 0.1000 - val_loss: 2.3046 - val_accuracy: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 2.3042 - accuracy: 0.1002 - val_loss: 2.3054 - val_accuracy: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 2.3043 - accuracy: 0.0993 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 2.3041 - accuracy: 0.1014 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 2.3041 - accuracy: 0.0998 - val_loss: 2.3053 - val_accuracy: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 11s 227us/step - loss: 2.3040 - accuracy: 0.0971 - val_loss: 2.3047 - val_accuracy: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.3040 - accuracy: 0.0988 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 2.3041 - accuracy: 0.1000 - val_loss: 2.3040 - val_accuracy: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 2.3040 - accuracy: 0.0988 - val_loss: 2.3040 - val_accuracy: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 2.3043 - accuracy: 0.0969 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 2.3045 - accuracy: 0.0969 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 2.3043 - accuracy: 0.0990 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 2.3039 - accuracy: 0.0981 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 11s 218us/step - loss: 2.3041 - accuracy: 0.0996 - val_loss: 2.3042 - val_accuracy: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 2.3043 - accuracy: 0.0981 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 12s 245us/step - loss: 2.3041 - accuracy: 0.0980 - val_loss: 2.3050 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accurcy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3dc05b0d2992>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accurcy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mvalid_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accurcy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accurcy'"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"\n",
    "使用迴圈，建立不同 Learning rate 的模型並訓練\n",
    "\"\"\"\n",
    "for lr in LEARNING_RATE:\n",
    "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "    print(\"Experiment with LR = %.6f\" % (lr))\n",
    "    model = build_mlp(input_shape=x_train.shape[1:])\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.SGD(lr=lr, nesterov=True, momentum=MOMENTUM)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "    \n",
    "    # Collect results\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    valid_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"accurcy\"]\n",
    "    valid_acc = model.history.history[\"accurcy\"]\n",
    "    \n",
    "    exp_name_tag = \"exp-lr-%s\" % str(lr)\n",
    "    results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                             'valid-loss': valid_loss,\n",
    "                             'train-accurcy': train_acc,\n",
    "                             'valid-accurcy': valid_acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-accuracy'])),results[cond]['train-accuracy'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-accuracy'])),results[cond]['valid-accuracy'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
